# ReID Embedding Extractor - PyTorch ìµœì‹  ë²„ì „ í˜¸í™˜

SOLIDER_REID ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ëŒ ì´ë¯¸ì§€ì—ì„œ ReID(Re-identification) ì„ë² ë”©ì„ ì¶”ì¶œí•˜ëŠ” ìµœì í™”ëœ ë„êµ¬ì…ë‹ˆë‹¤. PyTorch 2.0+ ë²„ì „ê³¼ ì™„ì „íˆ í˜¸í™˜ë©ë‹ˆë‹¤.

## ğŸš€ ì£¼ìš” ê¸°ëŠ¥

- **PyTorch ìµœì‹  ë²„ì „ í˜¸í™˜**: PyTorch 2.0+ ì™„ì „ ì§€ì›
- **ë‹¨ì¼ ì´ë¯¸ì§€ ì„ë² ë”© ì¶”ì¶œ**: ê°œë³„ ì´ë¯¸ì§€ì—ì„œ ReID ì„ë² ë”© ì¶”ì¶œ
- **íš¨ìœ¨ì ì¸ ë°°ì¹˜ ì²˜ë¦¬**: `@torch.inference_mode()` ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ
- **ìœ ì‚¬ë„ ê³„ì‚°**: ì„ë² ë”© ê°„ ìœ ì‚¬ë„ ì¸¡ì • ë° ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°
- **ë‹¤ì–‘í•œ ì¶œë ¥ í˜•ì‹**: NumPy, JSON, í…ìŠ¤íŠ¸ í˜•ì‹ ì§€ì›
- **GPU/CPU ì§€ì›**: CUDA ë° CPU í™˜ê²½ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥
- **ìµœì í™”ëœ ì „ì²˜ë¦¬**: ìµœì‹  torchvision InterpolationMode ì‚¬ìš©

## ğŸ“¦ ì„¤ì¹˜

### 1. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

### 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ì„ íƒì‚¬í•­)

```bash
pip install -e .
```

## ğŸ¯ ì‚¬ìš©ë²•

### 1. ëª…ë ¹í–‰ ì¸í„°í˜ì´ìŠ¤

#### ê¸°ë³¸ ì‚¬ìš©ë²•
```bash
python inference.py \
    --model_path path/to/trained_model.pth \
    --input path/to/image.jpg \
    --output embeddings.npy
```

#### ì—¬ëŸ¬ ì´ë¯¸ì§€ ì²˜ë¦¬
```bash
python inference.py \
    --model_path path/to/trained_model.pth \
    --input path/to/image_folder/ \
    --output embeddings.npy \
    --output_format json \
    --batch_size 32
```

#### ê³ ê¸‰ ì˜µì…˜
```bash
python inference.py \
    --model_path path/to/trained_model.pth \
    --input path/to/images/ \
    --config_path path/to/config.yml \
    --output embeddings.npy \
    --device cuda \
    --semantic_weight 0.2 \
    --image_size 384 128 \
    --batch_size 16 \
    --normalize
```

### 2. Python API ì‚¬ìš©

```python
from embedding_extractor import ReIDEmbeddingExtractor
import numpy as np

# ì„ë² ë”© ì¶”ì¶œê¸° ì´ˆê¸°í™”
extractor = ReIDEmbeddingExtractor(
    model_path="path/to/trained_model.pth",
    config_path="path/to/config.yml",
    device="cuda",  # ë˜ëŠ” None (ìë™ ì„ íƒ)
    semantic_weight=0.2,
    image_size=(384, 128),
    normalize_features=True
)

# ë‹¨ì¼ ì´ë¯¸ì§€ ì„ë² ë”© ì¶”ì¶œ
embedding = extractor.extract_embedding("path/to/image.jpg")
print(f"ì„ë² ë”© ì°¨ì›: {len(embedding)}")

# ì—¬ëŸ¬ ì´ë¯¸ì§€ ë°°ì¹˜ ì²˜ë¦¬
image_paths = ["img1.jpg", "img2.jpg", "img3.jpg"]
embeddings = extractor.extract_embeddings_batch(image_paths, batch_size=32)

# ìœ ì‚¬ë„ ê³„ì‚°
similarity = extractor.compute_similarity(embeddings[0], embeddings[1])
print(f"ìœ ì‚¬ë„: {similarity:.4f}")

# ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°
similarity_matrix = extractor.compute_similarity_matrix(embeddings[:2], embeddings[2:])
print(f"ìœ ì‚¬ë„ í–‰ë ¬ í¬ê¸°: {similarity_matrix.shape}")

# ê°€ì¥ ìœ ì‚¬í•œ ì´ë¯¸ì§€ ì°¾ê¸°
query_embedding = embeddings[0]
gallery_embeddings = embeddings[1:]
best_idx, best_sim = extractor.find_most_similar(query_embedding, gallery_embeddings)
print(f"ê°€ì¥ ìœ ì‚¬í•œ ì´ë¯¸ì§€: {best_idx}, ìœ ì‚¬ë„: {best_sim:.4f}")
```

## âš™ï¸ ì„¤ì •

### ëª¨ë¸ ì„¤ì • (YAML íŒŒì¼)

```yaml
MODEL:
  NAME: 'transformer'
  TRANSFORMER_TYPE: 'swin_base_patch4_window7_224'
  SEMANTIC_WEIGHT: 0.2

INPUT:
  SIZE_TRAIN: [384, 128]
  SIZE_TEST: [384, 128]
  PIXEL_MEAN: [0.5, 0.5, 0.5]
  PIXEL_STD: [0.5, 0.5, 0.5]

TEST:
  NECK_FEAT: 'before'
  FEAT_NORM: 'yes'
```

### ëª…ë ¹í–‰ ì¸ì

| ì¸ì | ì„¤ëª… | ê¸°ë³¸ê°’ |
|------|------|--------|
| `--model_path` | í›ˆë ¨ëœ ëª¨ë¸ ê²½ë¡œ | í•„ìˆ˜ |
| `--input` | ì…ë ¥ ì´ë¯¸ì§€/í´ë” ê²½ë¡œ | í•„ìˆ˜ |
| `--output` | ì¶œë ¥ íŒŒì¼ ê²½ë¡œ | `embeddings.npy` |
| `--config_path` | ì„¤ì • íŒŒì¼ ê²½ë¡œ | `default_config.yml` |
| `--device` | ì‚¬ìš© ë””ë°”ì´ìŠ¤ | ìë™ ì„ íƒ |
| `--semantic_weight` | ì‹œë§¨í‹± ê°€ì¤‘ì¹˜ | `0.2` |
| `--image_size` | ì´ë¯¸ì§€ í¬ê¸° | `384 128` |
| `--batch_size` | ë°°ì¹˜ í¬ê¸° | `32` |
| `--output_format` | ì¶œë ¥ í˜•ì‹ | `npy` |
| `--normalize` | L2 ì •ê·œí™” | `True` |

## ğŸ”§ PyTorch ìµœì‹  ë²„ì „ ê°œì„ ì‚¬í•­

### 1. ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
```python
@torch.inference_mode()  # PyTorch 1.9+ì—ì„œ ê¶Œì¥
def extract_embedding(self, image):
    # ì¶”ë¡  ëª¨ë“œë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
    pass
```

### 2. ìµœì‹  torchvision í˜¸í™˜
```python
# ìµœì‹  InterpolationMode ì‚¬ìš©
transforms.Resize(
    image_size, 
    interpolation=transforms.InterpolationMode.BICUBIC
)
```

### 3. íƒ€ì… íŒíŠ¸ ê°œì„ 
```python
def extract_embedding(
    self, 
    image: Union[str, Image.Image, np.ndarray]
) -> np.ndarray:
    # ëª…í™•í•œ íƒ€ì… íŒíŠ¸ë¡œ ì½”ë“œ ê°€ë…ì„± í–¥ìƒ
    pass
```

### 4. ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”
```python
try:
    from model import make_model
    from config import cfg
except ImportError as e:
    print(f"SOLIDER_REID ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    sys.exit(1)
```

## ğŸ“ ì¶œë ¥ í˜•ì‹

### 1. NumPy í˜•ì‹ (.npy)
```python
import numpy as np
embeddings = np.load("embeddings.npy")
print(embeddings.shape)  # (num_images, embedding_dim)
```

### 2. JSON í˜•ì‹ (.json)
```json
{
  "embeddings": [[0.1, 0.2, ...], [0.3, 0.4, ...]],
  "image_paths": ["img1.jpg", "img2.jpg"],
  "embedding_dim": 2048
}
```

### 3. í…ìŠ¤íŠ¸ í˜•ì‹ (.txt)
```
# Image 0: img1.jpg
0.1 0.2 0.3 ...

# Image 1: img2.jpg
0.4 0.5 0.6 ...
```

## ğŸ”§ ê³ ê¸‰ ì‚¬ìš©ë²•

### 1. ì»¤ìŠ¤í…€ ì „ì²˜ë¦¬

```python
from PIL import Image
import torchvision.transforms as T

# ì»¤ìŠ¤í…€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
custom_transform = T.Compose([
    T.Resize((384, 128), interpolation=T.InterpolationMode.BICUBIC),
    T.ColorJitter(brightness=0.2, contrast=0.2),
    T.ToTensor(),
    T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬
image = Image.open("image.jpg")
processed = custom_transform(image)
```

### 2. ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”

```python
# í° ë°ì´í„°ì…‹ì˜ ê²½ìš° ë°°ì¹˜ í¬ê¸° ì¡°ì •
embeddings = extractor.extract_embeddings_batch(
    image_paths, 
    batch_size=64  # GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •
)
```

### 3. ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì²˜ë¦¬

```python
# ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ì²˜ë¦¬
def process_large_dataset(image_paths, batch_size=32):
    all_embeddings = []
    
    for i in range(0, len(image_paths), batch_size):
        batch_paths = image_paths[i:i + batch_size]
        batch_embeddings = extractor.extract_embeddings_batch(batch_paths)
        all_embeddings.extend(batch_embeddings)
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        torch.cuda.empty_cache()
    
    return all_embeddings
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### 1. GPU ì‚¬ìš©
```python
# CUDA ì‚¬ìš© ì‹œ
extractor = ReIDEmbeddingExtractor(
    model_path="model.pth",
    config_path="config.yml",
    device="cuda"
)
```

### 2. ë°°ì¹˜ í¬ê¸° ì¡°ì •
- GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ë°°ì¹˜ í¬ê¸° ì¡°ì •
- ì¼ë°˜ì ìœ¼ë¡œ 16-64 ì‚¬ì´ì—ì„œ ìµœì  ì„±ëŠ¥

### 3. ì¶”ë¡  ëª¨ë“œ ì‚¬ìš©
```python
# @torch.inference_mode() ìë™ ì ìš©
# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” ë° ì„±ëŠ¥ í–¥ìƒ
```

## ğŸ› ë¬¸ì œ í•´ê²°

### 1. CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
python inference.py --batch_size 8

# CPU ì‚¬ìš©
python inference.py --device cpu
```

### 2. ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨
```python
# ëª¨ë¸ íŒŒì¼ ê²½ë¡œ í™•ì¸
import os
print(os.path.exists("path/to/model.pth"))

# ì„¤ì • íŒŒì¼ í™•ì¸
print(os.path.exists("path/to/config.yml"))
```

### 3. ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨
```python
# ì§€ì›ë˜ëŠ” ì´ë¯¸ì§€ í˜•ì‹ í™•ì¸
from PIL import Image
try:
    img = Image.open("image.jpg")
    print("ì´ë¯¸ì§€ ë¡œë“œ ì„±ê³µ")
except Exception as e:
    print(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
```

### 4. PyTorch ë²„ì „ í˜¸í™˜ì„±
```python
import torch
print(f"PyTorch ë²„ì „: {torch.__version__}")

# ìµœì†Œ ìš”êµ¬ì‚¬í•­: PyTorch 2.0+
if torch.__version__ < "2.0.0":
    print("PyTorch 2.0 ì´ìƒ ë²„ì „ì„ ì‚¬ìš©í•˜ì„¸ìš”")
```

## ğŸ“ ì˜ˆì œ

ìì„¸í•œ ì‚¬ìš© ì˜ˆì œëŠ” `example_usage.py`ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”:

```bash
python example_usage.py
```

## ğŸ”„ ë²„ì „ ì—…ë°ì´íŠ¸

### v1.0.0 (PyTorch ìµœì‹  ë²„ì „ í˜¸í™˜)
- PyTorch 2.0+ ì™„ì „ ì§€ì›
- `@torch.inference_mode()` ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ
- ìµœì‹  torchvision InterpolationMode ì‚¬ìš©
- íƒ€ì… íŒíŠ¸ ê°œì„ 
- ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”
- ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”

## ğŸ¤ ê¸°ì—¬

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License

## ğŸ“ ì§€ì›

ë¬¸ì œê°€ ìˆê±°ë‚˜ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì´ìŠˆë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.