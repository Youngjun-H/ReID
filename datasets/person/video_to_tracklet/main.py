import cv2
import time
from pathlib import Path
from detector import PersonDetector
from cropper import save_tracklets
from metadata_writer import append_metadata
from visualizer import ProgressVisualizer

def process_video(video_path, cam_id="cam01", out_dir="dataset_raw", conf=0.85, frame_interval=1):
    detector = PersonDetector(conf=conf)
    cap = cv2.VideoCapture(video_path)
    
    # ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    reported_total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    
    # FPS ë° ì´ í”„ë ˆìž„ ìˆ˜ ê²€ì¦
    print(f"ðŸ“Š OpenCV ë³´ê³  ì •ë³´:")
    print(f"   ðŸ“ ë³´ê³ ëœ ì´ í”„ë ˆìž„: {reported_total_frames:,}")
    print(f"   â±ï¸  ë³´ê³ ëœ FPS: {fps:.1f}")
    
    # ì‹¤ì œ FPSì™€ ì´ í”„ë ˆìž„ ìˆ˜ë¥¼ ê³„ì‚°
    print("ðŸ” ì‹¤ì œ ë¹„ë””ì˜¤ ì •ë³´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤...")
    
    # ì²˜ìŒ 100í”„ë ˆìž„ìœ¼ë¡œ FPS ê³„ì‚°
    test_frames = 100
    start_time = time.time()
    actual_frames_counted = 0
    
    for i in range(test_frames):
        ret, _ = cap.read()
        if not ret:
            break
        actual_frames_counted += 1
    
    end_time = time.time()
    
    if end_time > start_time and actual_frames_counted > 0:
        actual_fps = actual_frames_counted / (end_time - start_time)
        print(f"   âœ… ê³„ì‚°ëœ ì‹¤ì œ FPS: {actual_fps:.1f}")
        fps = actual_fps
    else:
        fps = 30.0  # ê¸°ë³¸ê°’ ì‚¬ìš©
        print(f"   âš ï¸  ê¸°ë³¸ FPS ì‚¬ìš©: {fps}")
    
    # AVI íŒŒì¼ì˜ ê²½ìš° ë” ì—„ê²©í•œ ê²€ì¦ í•„ìš”
    video_extension = Path(video_path).suffix.lower()
    is_avi = video_extension == '.avi'
    
    if is_avi:
        print(f"   ðŸŽ¬ AVI íŒŒì¼ ê°ì§€: ë™ì  ê³„ì‚° ëª¨ë“œë¡œ ê°•ì œ ì „í™˜")
        print(f"   ðŸ“Š ë³´ê³ ëœ í”„ë ˆìž„ ìˆ˜: {reported_total_frames:,} (ì‹ ë¢°í•˜ì§€ ì•ŠìŒ)")
        print(f"   ðŸ’¡ AVI íŒŒì¼ì€ OpenCVì—ì„œ ë¶€ì •í™•í•œ í”„ë ˆìž„ ìˆ˜ë¥¼ ë³´ê³ í•˜ëŠ” ê²½ìš°ê°€ ë§ŽìŠµë‹ˆë‹¤")
        total_frames = -1  # AVIëŠ” í•­ìƒ ë™ì  ê³„ì‚° ëª¨ë“œ
    else:
        # MP4 ë“± ë‹¤ë¥¸ í¬ë§·
        if reported_total_frames > 0 and reported_total_frames < 1000000:  # í•©ë¦¬ì ì¸ ë²”ìœ„
            total_frames = reported_total_frames
            print(f"   âœ… OpenCV ë³´ê³  í”„ë ˆìž„ ìˆ˜ ì‚¬ìš©: {total_frames:,}")
        else:
            print(f"   âš ï¸  OpenCV ë³´ê³  í”„ë ˆìž„ ìˆ˜ê°€ ë¹„ì •ìƒì ìž…ë‹ˆë‹¤ ({reported_total_frames:,})")
            print("   ðŸ“ ë™ì  ê³„ì‚° ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤...")
            total_frames = -1  # ë™ì  ê³„ì‚° ëª¨ë“œ
    
    # ë¹„ë””ì˜¤ ìº¡ì²˜ ìž¬ì‹œìž‘
    cap.release()
    cap = cv2.VideoCapture(video_path)
    
    # ì‹œê°í™” ë„êµ¬ ì´ˆê¸°í™”
    visualizer = ProgressVisualizer(video_path, total_frames, fps, conf, out_dir, cam_id, frame_interval)
    visualizer.print_video_info()

    frame_count = 0
    processed_frames = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame_count += 1
        
        # frame_intervalì— ë”°ë¼ ì²˜ë¦¬ ì—¬ë¶€ ê²°ì •
        if frame_count % frame_interval == 0:
            processed_frames += 1
            
            # YOLO ë‚´ìž¥ tracking ì‚¬ìš©
            boxes, confs, track_ids = detector.track(frame)
            
            # tracking ê²°ê³¼ë¥¼ ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            tracks = []
            for i, (box, conf, tid) in enumerate(zip(boxes, confs, track_ids)):
                x1, y1, x2, y2 = box
                tracks.append((x1, y1, x2, y2, tid, conf))

            # ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸ (ì²˜ë¦¬ëœ í”„ë ˆìž„ ìˆ˜ ì¦ê°€)
            visualizer.update_progress(tracks, frame_count, processed_frames)
            
            # ì´ë¯¸ì§€ ì €ìž¥ ë° ë©”íƒ€ë°ì´í„° ê¸°ë¡
            timestamp = time.strftime("%Y-%m-%dT%H:%M:%S")
            frame_id = visualizer.get_frame_id()
            save_tracklets(frame, tracks, cam_id, out_dir, frame_id, timestamp)

            for x1, y1, x2, y2, tid, conf in tracks:
                append_metadata(cam_id, tid, frame_id, conf, timestamp, out_dir)
        else:
            # ì²˜ë¦¬í•˜ì§€ ì•ŠëŠ” í”„ë ˆìž„ì€ ë¹ˆ tracksë¡œ ì§„í–‰ìƒí™©ë§Œ ì—…ë°ì´íŠ¸
            visualizer.update_progress([], frame_count, processed_frames)

    cap.release()
    visualizer.close()

if __name__ == "__main__":
    import argparse


    parser = argparse.ArgumentParser(description="Extract tracklets from CCTV video")
    parser.add_argument("--video", type=str, required=True, help="Path to video file or RTSP stream")
    parser.add_argument("--cam-id", type=str, default="cam01")
    parser.add_argument("--out", type=str, default="dataset_raw")
    parser.add_argument("--conf", type=float, default=0.85)
    parser.add_argument("--frame-interval", type=int, default=1, 
                       help="Process every N frames (default: 1, process every frame)")
    args = parser.parse_args()

    process_video(args.video, args.cam_id, args.out, args.conf, args.frame_interval)