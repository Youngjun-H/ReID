from vllm import LLM, SamplingParams
from transformers import AutoProcessor
from PIL import Image
from qwen_vl_utils import process_vision_info
from pathlib import Path
from collections import Counter
import os
import argparse

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["HUGGINGFACE_HUB_CACHE"] = "/data/reid/reid_master/cache"

# ì§€ì›í•˜ëŠ” ì´ë¯¸ì§€ í™•ì¥ì
IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.webp'}

# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œ ì €ì¥ (ì¬ì‚¬ìš©ì„ ìœ„í•´)
_llm = None
_processor = None


def initialize_model(model_name="Qwen/Qwen3-VL-4B-Instruct", gpu_memory_utilization=0.9, max_model_len=2048):
    """
    ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    
    Args:
        model_name: ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
        gpu_memory_utilization: GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (ê¸°ë³¸ê°’: 0.9)
        max_model_len: ìµœëŒ€ ëª¨ë¸ ê¸¸ì´ (ê¸°ë³¸ê°’: 2048)
    
    Returns:
        tuple: (llm, processor)
    """
    global _llm, _processor
    
    if _processor is None:
        _processor = AutoProcessor.from_pretrained(model_name)
    
    if _llm is None:
        _llm = LLM(
            model=model_name,
            gpu_memory_utilization=gpu_memory_utilization,
            max_model_len=max_model_len,
        )
    
    return _llm, _processor


def prepare_inputs_for_vllm(messages, processor):
    """
    vLLMì— ì…ë ¥í•  ìˆ˜ ìˆëŠ” í˜•ì‹ìœ¼ë¡œ ë©”ì‹œì§€ë¥¼ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        messages: ì‚¬ìš©ì ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
        processor: AutoProcessor ê°ì²´
    
    Returns:
        dict: vLLM ì…ë ¥ í˜•ì‹
    """
    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    image_inputs, video_inputs, video_kwargs = process_vision_info(
        messages, 
        image_patch_size=processor.image_processor.patch_size, 
        return_video_kwargs=True, 
        return_video_metadata=True
    )
    mm_data = {}
    if image_inputs is not None:
        mm_data['image'] = image_inputs
    if video_inputs is not None:
        mm_data['video'] = video_inputs
    return {
        'prompt': text,
        'multi_modal_data': mm_data,
        'mm_processor_kwargs': video_kwargs
    }


def get_image_files(image_dir):
    """
    ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤.
    
    Args:
        image_dir: ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ
    
    Returns:
        list: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (ì •ë ¬ë¨)
    """
    image_dir = Path(image_dir)
    image_files = []
    
    for ext in IMAGE_EXTENSIONS:
        image_files.extend(image_dir.glob(f'*{ext}'))
        image_files.extend(image_dir.glob(f'*{ext.upper()}'))
    
    return sorted(image_files)


def process_images_in_directory(
    image_dir,
    prompt_text="ê¸€ìë¥¼ ì½ì–´ì¤˜.",
    llm=None,
    processor=None,
    model_name="Qwen/Qwen3-VL-4B-Instruct",
    gpu_memory_utilization=0.9,
    max_model_len=2048,
    temperature=0.8,
    max_tokens=256,
    save_label=True,
    verbose=True
):
    """
    ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  ì´ë¯¸ì§€ì— ëŒ€í•´ OCRì„ ìˆ˜í–‰í•˜ê³  ê°€ì¥ ë§ì´ ë°˜ë³µëœ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        image_dir: ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        prompt_text: OCR í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸
        llm: LLM ê°ì²´ (Noneì´ë©´ ìë™ ì´ˆê¸°í™”)
        processor: AutoProcessor ê°ì²´ (Noneì´ë©´ ìë™ ì´ˆê¸°í™”)
        model_name: ëª¨ë¸ ì´ë¦„
        gpu_memory_utilization: GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
        max_model_len: ìµœëŒ€ ëª¨ë¸ ê¸¸ì´
        temperature: ìƒ˜í”Œë§ ì˜¨ë„
        max_tokens: ìµœëŒ€ í† í° ìˆ˜
        save_label: label.txt íŒŒì¼ë¡œ ì €ì¥í• ì§€ ì—¬ë¶€
        verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
    
    Returns:
        dict: {
            'final_result': ìµœì¢… ê²°ê³¼ (ê°€ì¥ ë§ì´ ë°˜ë³µëœ ê²°ê³¼),
            'all_results': ëª¨ë“  ê²°ê³¼ ë¦¬ìŠ¤íŠ¸,
            'result_stats': ê²°ê³¼ í†µê³„ (Counter ê°ì²´),
            'image_files': ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        }
    """
    # ëª¨ë¸ ì´ˆê¸°í™”
    if llm is None or processor is None:
        llm, processor = initialize_model(model_name, gpu_memory_utilization, max_model_len)
    
    # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
    image_files = get_image_files(image_dir)
    
    if len(image_files) == 0:
        if verbose:
            print(f"ê²½ê³ : {image_dir}ì— ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {
            'final_result': None,
            'all_results': [],
            'result_stats': Counter(),
            'image_files': []
        }
    
    if verbose:
        print(f"ì´ {len(image_files)}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n")
    
    # ëª¨ë“  ì´ë¯¸ì§€ì— ëŒ€í•œ ì…ë ¥ ì¤€ë¹„
    inputs = []
    for img_path in image_files:
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": str(img_path)},
                    {"type": "text", "text": prompt_text}
                ]
            },
        ]
        inputs.append(prepare_inputs_for_vllm(messages, processor))
    
    # ìƒ˜í”Œë§ íŒŒë¼ë¯¸í„° ì„¤ì •
    sampling_params = SamplingParams(temperature=temperature, max_tokens=max_tokens)
    
    # ë°°ì¹˜ë¡œ ì²˜ë¦¬
    outputs = llm.generate(inputs, sampling_params=sampling_params)
    
    # ê²°ê³¼ ìˆ˜ì§‘
    results = []
    if verbose:
        print("=" * 80)
    
    for i, output in enumerate(outputs):
        img_path = image_files[i]
        result_text = output.outputs[0].text.strip()
        results.append(result_text)
        if verbose:
            print(f"\n[ì´ë¯¸ì§€ {i+1}/{len(outputs)}]: {img_path.name}")
            print(f"ê²°ê³¼: {result_text}")
            print("-" * 80)
    
    # ê°€ì¥ ë§ì´ ë°˜ë³µëœ ê²°ê³¼ ì°¾ê¸°
    result_counter = Counter(results)
    if len(result_counter) > 0:
        most_common_result, most_common_count = result_counter.most_common(1)[0]
    else:
        most_common_result = None
        most_common_count = 0
    
    # ê²°ê³¼ í†µê³„ ì¶œë ¥
    if verbose:
        print("\n" + "=" * 80)
        print("ğŸ“Š ê²°ê³¼ í†µê³„")
        print("=" * 80)
        if len(results) > 0:
            print(f"\nì´ {len(results)}ê°œì˜ ê²°ê³¼ ì¤‘ ê°€ì¥ ë§ì´ ë°˜ë³µëœ ê²°ê³¼:")
            print(f"  ê²°ê³¼: '{most_common_result}'")
            print(f"  ë°˜ë³µ íšŸìˆ˜: {most_common_count}íšŒ ({most_common_count/len(results)*100:.1f}%)")
            
            print(f"\nìƒìœ„ 5ê°œ ê²°ê³¼:")
            for result, count in result_counter.most_common(5):
                print(f"  '{result}': {count}íšŒ ({count/len(results)*100:.1f}%)")
        
        print("\n" + "=" * 80)
        print(f"âœ… ìµœì¢… ê²°ê³¼: '{most_common_result}'")
        print("=" * 80)
    
    # label.txt ì €ì¥
    if save_label and most_common_result is not None:
        label_file = Path(image_dir) / "label.txt"
        with open(label_file, 'w', encoding='utf-8') as f:
            f.write(most_common_result)
        if verbose:
            print(f"\nğŸ’¾ ìµœì¢… ê²°ê³¼ê°€ '{label_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return {
        'final_result': most_common_result,
        'all_results': results,
        'result_stats': result_counter,
        'image_files': image_files
    }


def main():
    """CLI ì¸í„°í˜ì´ìŠ¤"""
    parser = argparse.ArgumentParser(description='ë””ë ‰í† ë¦¬ ë‚´ ì´ë¯¸ì§€ì— ëŒ€í•´ OCRì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.')
    parser.add_argument('image_dir', type=str, help='ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    parser.add_argument('--prompt', type=str, default='ê¸€ìë¥¼ ì½ì–´ì¤˜.', help='OCR í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸')
    parser.add_argument('--model', type=str, default='Qwen/Qwen3-VL-4B-Instruct', help='ëª¨ë¸ ì´ë¦„')
    parser.add_argument('--gpu-memory', type=float, default=0.9, help='GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ')
    parser.add_argument('--max-model-len', type=int, default=2048, help='ìµœëŒ€ ëª¨ë¸ ê¸¸ì´')
    parser.add_argument('--temperature', type=float, default=0.8, help='ìƒ˜í”Œë§ ì˜¨ë„')
    parser.add_argument('--max-tokens', type=int, default=256, help='ìµœëŒ€ í† í° ìˆ˜')
    parser.add_argument('--no-save', action='store_true', help='label.txt ì €ì¥í•˜ì§€ ì•Šê¸°')
    parser.add_argument('--quiet', action='store_true', help='ìƒì„¸ ì¶œë ¥ ë¹„í™œì„±í™”')
    
    args = parser.parse_args()
    
    result = process_images_in_directory(
        image_dir=args.image_dir,
        prompt_text=args.prompt,
        model_name=args.model,
        gpu_memory_utilization=args.gpu_memory,
        max_model_len=args.max_model_len,
        temperature=args.temperature,
        max_tokens=args.max_tokens,
        save_label=not args.no_save,
        verbose=not args.quiet
    )
    
    if args.quiet:
        print(result['final_result'])


if __name__ == "__main__":
    main()
